{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Z88FfJc9lA_T",
   "metadata": {
    "id": "Z88FfJc9lA_T"
   },
   "source": [
    "## Analysis of an E-commerce Dataset Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hoq0NwA9lA_V",
   "metadata": {
    "id": "hoq0NwA9lA_V"
   },
   "source": [
    "The goal of the second analysis task is to train linear regression models to predict users' ratings towards items. This involves a standard Data Science workflow: exploring data, building models, making predictions, and evaluating results. In this task, we will explore the impacts of feature selections and different sizes of training/testing data on the model performance. We will use another cleaned combined e-commerce sub-dataset that **is different from** the one in “Analysis of an E-commerce Dataset” task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd3NU_lA_W",
   "metadata": {
    "id": "f9fd3NU_lA_W"
   },
   "source": [
    "### Import Cleaned E-commerce Dataset\n",
    "The csv file named 'cleaned_ecommerce_dataset.csv' is provided. You may need to use the Pandas method, i.e., `read_csv`, for reading it. After that, please print out its total length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22858941",
   "metadata": {},
   "source": [
    "<h1><b>Compiled and Created by : TAHA AHMED SIDDIQUI | 48189111</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d7ffa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "PJrb2gtAlA_W",
   "metadata": {
    "id": "PJrb2gtAlA_W"
   },
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv('C:/Users/BEYOND/Downloads/Portfolio part 2 resources-20240329/cleaned_ecommerce_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa05d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>review</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>user_city</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>71900</td>\n",
       "      <td>Not always McCrap</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>41</td>\n",
       "      <td>30.74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>72000</td>\n",
       "      <td>I dropped the chalupa even before he told me to</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>74</td>\n",
       "      <td>108.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>72000</td>\n",
       "      <td>The Wonderful World of Wendy</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>84</td>\n",
       "      <td>69.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>100399</td>\n",
       "      <td>They actually did it</td>\n",
       "      <td>South Park: Bigger, Longer &amp; Uncut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>68</td>\n",
       "      <td>143.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>100399</td>\n",
       "      <td>Hey! Gimme some pie!</td>\n",
       "      <td>American Pie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>6</td>\n",
       "      <td>117.89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>22000</td>\n",
       "      <td>Great movie!</td>\n",
       "      <td>Austin Powers: The Spy Who Shagged Me</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>9</td>\n",
       "      <td>111.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>30700</td>\n",
       "      <td>Good food!</td>\n",
       "      <td>Outback Steakhouse</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>50</td>\n",
       "      <td>25.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>61500</td>\n",
       "      <td>Great movie!</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>26</td>\n",
       "      <td>97.53</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>100500</td>\n",
       "      <td>Awesome Game.</td>\n",
       "      <td>The Sims 2: Open for Business for Windows</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Games</td>\n",
       "      <td>79</td>\n",
       "      <td>27.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>101400</td>\n",
       "      <td>Great Service.</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Personal Finance</td>\n",
       "      <td>52</td>\n",
       "      <td>38.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2685 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp                                           review  \\\n",
       "userId                                                               \n",
       "4081        71900                                Not always McCrap   \n",
       "4081        72000  I dropped the chalupa even before he told me to   \n",
       "4081        72000                     The Wonderful World of Wendy   \n",
       "4081       100399                             They actually did it   \n",
       "4081       100399                             Hey! Gimme some pie!   \n",
       "...           ...                                              ...   \n",
       "2445        22000                                     Great movie!   \n",
       "2445        30700                                       Good food!   \n",
       "2445        61500                                     Great movie!   \n",
       "2445       100500                                    Awesome Game.   \n",
       "2445       101400                                   Great Service.   \n",
       "\n",
       "                                             item  rating  helpfulness gender  \\\n",
       "userId                                                                          \n",
       "4081                                   McDonald's     4.0          3.0      M   \n",
       "4081                                    Taco Bell     1.0          4.0      M   \n",
       "4081                                      Wendy's     5.0          4.0      M   \n",
       "4081           South Park: Bigger, Longer & Uncut     5.0          3.0      M   \n",
       "4081                                 American Pie     3.0          3.0      M   \n",
       "...                                           ...     ...          ...    ...   \n",
       "2445        Austin Powers: The Spy Who Shagged Me     5.0          3.0      M   \n",
       "2445                           Outback Steakhouse     5.0          3.0      M   \n",
       "2445                                   Fight Club     5.0          3.0      M   \n",
       "2445    The Sims 2: Open for Business for Windows     5.0          4.0      M   \n",
       "2445                                       PayPal     5.0          3.0      M   \n",
       "\n",
       "                     category  item_id  item_price  user_city  \n",
       "userId                                                         \n",
       "4081    Restaurants & Gourmet       41       30.74          4  \n",
       "4081    Restaurants & Gourmet       74      108.30          4  \n",
       "4081    Restaurants & Gourmet       84       69.00          4  \n",
       "4081                   Movies       68      143.11          4  \n",
       "4081                   Movies        6      117.89          4  \n",
       "...                       ...      ...         ...        ...  \n",
       "2445                   Movies        9      111.00          5  \n",
       "2445    Restaurants & Gourmet       50       25.00          5  \n",
       "2445                   Movies       26       97.53          5  \n",
       "2445                    Games       79       27.00          5  \n",
       "2445         Personal Finance       52       38.00          5  \n",
       "\n",
       "[2685 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fcf9786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2685, 10)\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of rows and coloumns in the DataFrame (length)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqbuU6rglA_X",
   "metadata": {
    "id": "aqbuU6rglA_X"
   },
   "source": [
    "### Explore the Dataset\n",
    "\n",
    "* Use the methods, i.e., `head()` and `info()`, to have a rough picture about the data, e.g., how many columns, and the data types of each column.\n",
    "* As our goal is to predict ratings given other columns, please get the correlations between helpfulness/gender/category/review and rating by using the `corr()` method.\n",
    "\n",
    "  Hints: To get the correlations between different features, you may need to first convert the categorical features (i.e., gender, category and review) into numerial values. For doing this, you may need to import `OrdinalEncoder` from `sklearn.preprocessing` (refer to the useful exmaples [here](https://pbpython.com/categorical-encoding.html))\n",
    "* Please provide ___necessary explanations/analysis___ on the correlations, and figure out which are the ___most___ and ___least___ corrleated features regarding rating. Try to ___discuss___ how the correlation will affect the final prediction results, if we use these features to train a regression model for rating prediction. In what follows, we will conduct experiments to verify your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "W3PImHiElA_X",
   "metadata": {
    "id": "W3PImHiElA_X"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>review</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>user_city</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>71900</td>\n",
       "      <td>Not always McCrap</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>41</td>\n",
       "      <td>30.74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>72000</td>\n",
       "      <td>I dropped the chalupa even before he told me to</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>74</td>\n",
       "      <td>108.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>72000</td>\n",
       "      <td>The Wonderful World of Wendy</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>84</td>\n",
       "      <td>69.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>100399</td>\n",
       "      <td>They actually did it</td>\n",
       "      <td>South Park: Bigger, Longer &amp; Uncut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>68</td>\n",
       "      <td>143.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>100399</td>\n",
       "      <td>Hey! Gimme some pie!</td>\n",
       "      <td>American Pie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>6</td>\n",
       "      <td>117.89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp                                           review  \\\n",
       "userId                                                               \n",
       "4081        71900                                Not always McCrap   \n",
       "4081        72000  I dropped the chalupa even before he told me to   \n",
       "4081        72000                     The Wonderful World of Wendy   \n",
       "4081       100399                             They actually did it   \n",
       "4081       100399                             Hey! Gimme some pie!   \n",
       "\n",
       "                                      item  rating  helpfulness gender  \\\n",
       "userId                                                                   \n",
       "4081                            McDonald's     4.0          3.0      M   \n",
       "4081                             Taco Bell     1.0          4.0      M   \n",
       "4081                               Wendy's     5.0          4.0      M   \n",
       "4081    South Park: Bigger, Longer & Uncut     5.0          3.0      M   \n",
       "4081                          American Pie     3.0          3.0      M   \n",
       "\n",
       "                     category  item_id  item_price  user_city  \n",
       "userId                                                         \n",
       "4081    Restaurants & Gourmet       41       30.74          4  \n",
       "4081    Restaurants & Gourmet       74      108.30          4  \n",
       "4081    Restaurants & Gourmet       84       69.00          4  \n",
       "4081                   Movies       68      143.11          4  \n",
       "4081                   Movies        6      117.89          4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac1fa9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2685 entries, 4081 to 2445\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   timestamp    2685 non-null   int64  \n",
      " 1   review       2685 non-null   object \n",
      " 2   item         2685 non-null   object \n",
      " 3   rating       2685 non-null   float64\n",
      " 4   helpfulness  2685 non-null   float64\n",
      " 5   gender       2685 non-null   object \n",
      " 6   category     2685 non-null   object \n",
      " 7   item_id      2685 non-null   int64  \n",
      " 8   item_price   2685 non-null   float64\n",
      " 9   user_city    2685 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(4)\n",
      "memory usage: 230.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b9dc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BEYOND\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "260c1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features (gender, category, review) using OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "df[\"gender\"] = encoder.fit_transform(df[[\"gender\"]])\n",
    "df[\"category\"] = encoder.fit_transform(df[[\"category\"]])\n",
    "df[\"review\"] = encoder.fit_transform(df[[\"review\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d35ac2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             helpfulness    gender  category    review    rating\n",
      "helpfulness     1.000000  0.075947 -0.013408 -0.028259 -0.007523\n",
      "gender          0.075947  1.000000  0.022549 -0.037884 -0.034337\n",
      "category       -0.013408  0.022549  1.000000  0.001970 -0.163158\n",
      "review         -0.028259 -0.037884  0.001970  1.000000 -0.036118\n",
      "rating         -0.007523 -0.034337 -0.163158 -0.036118  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate correlations between features and rating\n",
    "correlations = df[[\"helpfulness\", \"gender\", \"category\", \"review\", \"rating\"]].corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caffcdb",
   "metadata": {},
   "source": [
    "<h1>Discussion:</h1>\n",
    "<ul><li>Most correlated feature:\n",
    "\n",
    "The \"category\" feature has the highest negative correlation with the \"rating\" variable, with a correlation coefficient of approximately -0.163. This indicates that there's a moderate negative correlation between the category of the product and its rating.</li>\n",
    "<li>Least correlated feature:\n",
    "\n",
    "The \"helpfulness\" feature has the least correlation with the \"rating\" variable, with a correlation coefficient of approximately -0.0075. This suggests that there's a very weak correlation between the helpfulness of the review and the rating of the product.</li></ul>\n",
    "\n",
    "<h2>Impact on Prediction Results:</h2>\n",
    "<ul><li>\n",
    "When training a regression model for rating prediction, including highly correlated features like \"category\" can improve the model's predictive power. By capturing the relationship between product categories and ratings, the model can make more accurate predictions for products within those categories.</li><li>\n",
    "Conversely, including features like \"helpfulness,\" which have weak correlations with the target variable, might not contribute much to the model's performance. In fact, it could potentially lead to overfitting if the model tries to learn noise in the data.</li></ul>\n",
    "\n",
    "<h2>Experimental Verification:</h2>\n",
    "<ul><li>\n",
    "To verify these hypotheses, we can conduct experiments by building regression models with different combinations of features, including or excluding \"category\" and \"helpfulness.\"</li><li>\n",
    "We can evaluate the models using appropriate metrics such as mean squared error (MSE) to compare their performance.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4myP5igslA_Y",
   "metadata": {
    "id": "4myP5igslA_Y"
   },
   "source": [
    "### Split Training and Testing Data\n",
    "* Machine learning models are trained to help make predictions for the future. Normally, we need to randomly split the dataset into training and testing sets, where we use the training set to train the model, and then leverage the well-trained model to make predictions on the testing set.\n",
    "* To further investigate whether the size of the training/testing data affects the model performance, please random split the data into training and testing sets with different sizes:\n",
    "    * Case 1: training data containing 10% of the entire data;\n",
    "    * Case 2: training data containing 90% of the entire data.\n",
    "* Print the shape of training and testing sets in the two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49f09c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size1 = 0.1  # Case 1: 10% training data\n",
    "train_size2 = 0.9  # Case 2: 90% training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "JIDMig9blA_Y",
   "metadata": {
    "id": "JIDMig9blA_Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1 (Training 10%):\n",
      "X_train1 shape: (268, 9)\n",
      "y_train1 shape: (268,)\n",
      "X_test1 shape: (2417, 9)\n",
      "y_test1 shape: (2417,)\n",
      "\n",
      "\n",
      "Case 2 (Training 90%):\n",
      "X_train2 shape: (2416, 9)\n",
      "y_train2 shape: (2416,)\n",
      "X_test2 shape: (269, 9)\n",
      "y_test2 shape: (269,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (Case 1)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    df.drop(\"rating\", axis=1),  \n",
    "    df[\"rating\"],  \n",
    "    test_size=1 - train_size1, \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "print(\"Case 1 (Training 10%):\")\n",
    "print(f\"X_train1 shape: {X_train1.shape}\")\n",
    "print(f\"y_train1 shape: {y_train1.shape}\")\n",
    "print(f\"X_test1 shape: {X_test1.shape}\")\n",
    "print(f\"y_test1 shape: {y_test1.shape}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# (Case 2)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    df.drop(\"rating\", axis=1),\n",
    "    df[\"rating\"],\n",
    "    test_size=1 - train_size2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Case 2 (Training 90%):\")\n",
    "print(f\"X_train2 shape: {X_train2.shape}\")\n",
    "print(f\"y_train2 shape: {y_train2.shape}\")\n",
    "print(f\"X_test2 shape: {X_test2.shape}\")\n",
    "print(f\"y_test2 shape: {y_test2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DjSsgT0BlA_Y",
   "metadata": {
    "id": "DjSsgT0BlA_Y"
   },
   "source": [
    "### Train Linear Regression Models with Feature Selection under Cases 1 & 2\n",
    "* When training a machine learning model for prediction, we may need to select the most important/correlated input features for more accurate results.\n",
    "* To investigate whether feature selection affects the model performance, please select two most correlated features and two least correlated features from helpfulness/gender/category/review regarding rating, respectively.\n",
    "* Train four linear regression models by following the conditions:\n",
    "    - (model-a) using the training/testing data in case 1 with two most correlated input features\n",
    "    - (model-b) using the training/testing data in case 1 with two least correlated input features\n",
    "    - (model-c) using the training/testing data in case 2 with two most correlated input features\n",
    "    - (model-d) using the training/testing data in case 2 with two least correlated input features\n",
    "* By doing this, we can verify the impacts of the size of traing/testing data on the model performance via comparing model-a and model-c (or model-b and model-d); meanwhile the impacts of feature selection can be validated via comparing model-a and model-b (or model-c and model-d).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "DASzPUATlA_Z",
   "metadata": {
    "id": "DASzPUATlA_Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-a (Case 1 with two most correlated features) MSE: 1.776581354691434\n",
      "Model-b (Case 1 with two least correlated features) MSE: 1.860535990321889\n",
      "Model-c (Case 2 with two most correlated features) MSE: 1.681992500504392\n",
      "Model-d (Case 2 with two least correlated features) MSE: 1.7245375467700426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Selecting features for model-a and model-c (two most correlated features)\n",
    "most_correlated_features = ['category', 'review']\n",
    "\n",
    "# Selecting features for model-b and model-d (two least correlated features)\n",
    "least_correlated_features = ['helpfulness', 'gender']\n",
    "\n",
    "# Training model-a\n",
    "model_a = LinearRegression()\n",
    "model_a.fit(X_train_case1[most_correlated_features], y_train_case1)\n",
    "\n",
    "# Training model-b\n",
    "model_b = LinearRegression()\n",
    "model_b.fit(X_train_case1[least_correlated_features], y_train_case1)\n",
    "\n",
    "# Training model-c\n",
    "model_c = LinearRegression()\n",
    "model_c.fit(X_train_case2[most_correlated_features], y_train_case2)\n",
    "\n",
    "# Training model-d\n",
    "model_d = LinearRegression()\n",
    "model_d.fit(X_train_case2[least_correlated_features], y_train_case2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_a = model_a.predict(X_test_case1[most_correlated_features])\n",
    "y_pred_b = model_b.predict(X_test_case1[least_correlated_features])\n",
    "y_pred_c = model_c.predict(X_test_case2[most_correlated_features])\n",
    "y_pred_d = model_d.predict(X_test_case2[least_correlated_features])\n",
    "\n",
    "# Evaluate the models\n",
    "mse_a = mean_squared_error(y_test_case1, y_pred_a)\n",
    "mse_b = mean_squared_error(y_test_case1, y_pred_b)\n",
    "mse_c = mean_squared_error(y_test_case2, y_pred_c)\n",
    "mse_d = mean_squared_error(y_test_case2, y_pred_d)\n",
    "\n",
    "print(\"Model-a (Case 1 with two most correlated features) MSE:\", mse_a)\n",
    "print(\"Model-b (Case 1 with two least correlated features) MSE:\", mse_b)\n",
    "print(\"Model-c (Case 2 with two most correlated features) MSE:\", mse_c)\n",
    "print(\"Model-d (Case 2 with two least correlated features) MSE:\", mse_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KATSn7hYlA_Z",
   "metadata": {
    "id": "KATSn7hYlA_Z"
   },
   "source": [
    "### Evaluate Models\n",
    "* Evaluate the performance of the four models with two metrics, including MSE and Root MSE\n",
    "* Print the results of the four models regarding the two metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fU8GPS9lA_Z",
   "metadata": {
    "id": "4fU8GPS9lA_Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-a (Case 1 with two most correlated features) MSE: 1.776581354691434 RMSE: 1.3328845991650717\n",
      "Model-b (Case 1 with two least correlated features) MSE: 1.860535990321889 RMSE: 1.3640146591301316\n",
      "Model-c (Case 2 with two most correlated features) MSE: 1.681992500504392 RMSE: 1.2969165356739007\n",
      "Model-d (Case 2 with two least correlated features) MSE: 1.7245375467700426 RMSE: 1.3132164889194937\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate MSE for each model\n",
    "mse_a = mean_squared_error(y_test_case1, y_pred_a)\n",
    "mse_b = mean_squared_error(y_test_case1, y_pred_b)\n",
    "mse_c = mean_squared_error(y_test_case2, y_pred_c)\n",
    "mse_d = mean_squared_error(y_test_case2, y_pred_d)\n",
    "\n",
    "# Calculate RMSE for each model\n",
    "rmse_a = np.sqrt(mse_a)\n",
    "rmse_b = np.sqrt(mse_b)\n",
    "rmse_c = np.sqrt(mse_c)\n",
    "rmse_d = np.sqrt(mse_d)\n",
    "\n",
    "# Print the results\n",
    "print(\"Model-a (Case 1 with two most correlated features) MSE:\", mse_a, \"RMSE:\", rmse_a)\n",
    "print(\"Model-b (Case 1 with two least correlated features) MSE:\", mse_b, \"RMSE:\", rmse_b)\n",
    "print(\"Model-c (Case 2 with two most correlated features) MSE:\", mse_c, \"RMSE:\", rmse_c)\n",
    "print(\"Model-d (Case 2 with two least correlated features) MSE:\", mse_d, \"RMSE:\", rmse_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y9jx-eY6lA_a",
   "metadata": {
    "id": "Y9jx-eY6lA_a"
   },
   "source": [
    "### Visualize, Compare and Analyze the Results\n",
    "* Visulize the results, and perform ___insightful analysis___ on the obtained results. For better visualization, you may need to carefully set the scale for the y-axis.\n",
    "* Normally, the model trained with most correlated features and more training data will get better results. Do you obtain the similar observations? If not, please ___explain the possible reasons___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3TNAIGDilA_a",
   "metadata": {
    "id": "3TNAIGDilA_a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define model labels\n",
    "model_labels = ['Model-a', 'Model-b', 'Model-c', 'Model-d']\n",
    "\n",
    "# Define MSE and RMSE values\n",
    "mse_values = [mse_a, mse_b, mse_c, mse_d]\n",
    "rmse_values = [rmse_a, rmse_b, rmse_c, rmse_d]\n",
    "\n",
    "# Create bar plots for MSE and RMSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(model_labels, mse_values, color=['blue', 'green', 'red', 'orange'])\n",
    "plt.title('Mean Squared Error (MSE)')\n",
    "plt.ylabel('MSE')\n",
    "plt.ylim(0, max(mse_values) * 1.2)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(model_labels, rmse_values, color=['blue', 'green', 'red', 'orange'])\n",
    "plt.title('Root Mean Squared Error (RMSE)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim(0, max(rmse_values) * 1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f80335b",
   "metadata": {},
   "source": [
    "<b>As expected, the model trained with the most correlated features (model-a and model-c) tends to have lower MSE and RMSE values compared to the models trained with the least correlated features (model-b and model-d).</b>\n",
    "\n",
    "<b>The results obtained are quiet shocking due to following reasons:</b>\n",
    "   <ul><li> The dataset might not be large enough to benefit significantly from additional training data.</li>\n",
    "<li>The selected features might not capture all the relevant information necessary for accurate prediction, leading to limited improvement with more training data.</li>\n",
    "<li>The relationship between the features and the target variable might not be linear, making linear regression less effective, regardless of the amount of training data.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ee01ac",
   "metadata": {
    "id": "f9ee01ac"
   },
   "source": [
    "### Data Science Ethics\n",
    "*Please read the following examples [Click here to read the example_1.](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) [Click here to read the example_2.](https://viborc.com/ethics-and-ethical-data-visualization-a-complete-guide/)\n",
    "\n",
    "*Then view the picture ![My Image](figure_portfolio2.png \"This is my image\")\n",
    "Please compose an analysis of 100-200 words that evaluates potential ethical concerns associated with the infographic, detailing the reasons behind these issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8993bfce",
   "metadata": {
    "id": "44f30e9b"
   },
   "source": [
    "<b>The ethical implications of data manipulation, transparency, and potential biases are raised by the COVID-19 infographic about Georgia. The graph, which involves backdating positive test results, changing scales, and combining tests, has the potential to mislead the public and hinder informed decision-making. To address these concerns, it is essential to maintain transparency, establish clear data presentation policies, and acknowledge potential biases in data collection.</b>\n",
    "\n",
    "\n",
    "<b>The infographic regarding ethics and ethical data visualization is informative, but it raises certain ethical concerns. It oversimplifies intricate ethical principles, lacks an ethical framework that is universally applicable, does not account for the implications of privacy and consent, and does not consider the diversity of culture or language. To address these concerns, the guide should delve into more nuanced discussions, emphasize contextual knowledge, feature a section on privacy and data consent, and consider diversity in data visualization. </b>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
